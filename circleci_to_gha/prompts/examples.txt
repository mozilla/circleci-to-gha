# Example Successful Migration

```yaml
version: 2.1

orbs:
  gcp-gcr: circleci/gcp-gcr@0.11.0

jobs:
  test:
    docker:
      - image: cimg/python:3.11
    steps:
      - checkout
      - run: make test
  
  build-push:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - gcp-gcr/build-and-push-image:
          image: my-app
          registry-url: gcr.io
```

After (GH Actions)

```yaml
name: CI/CD

on:
  push:
    branches: [main]
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: make test

  build-push:
    if: github.ref == 'refs/heads/main'
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: docker build . -t us-docker.pkg.dev/moz-fx-data-artifacts-prod/my-repo/my-app:latest
      - name: Push to GAR
        uses: mozilla-it/deploy-actions/docker-push@v4.3.2
        with:
          project_id: moz-fx-data-artifacts-prod
          image_tags: us-docker.pkg.dev/moz-fx-data-artifacts-prod/my-repo/my-app:latest
          workload_identity_pool_project_number: ${{ vars.GCPV2_WORKLOAD_IDENTITY_POOL_PROJECT_NUMBER }}
          service_account_name: my-repo
```

# Example 2 Successful Migration

```yaml
version: 2.1

# See https://circleci.com/orbs/registry/orb/circleci/gcp-gcr
orbs:
  gcp-gcr: circleci/gcp-gcr@0.16.10

jobs:
  build:
    docker:
    - image: python:3.10
    steps:
    - checkout
    - restore_cache:
        keys:
          # when lock files change, use increasingly general patterns to restore cache
          - &cache_key
            python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
          - python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-
          - python-packages-v1-{{ .Branch }}-
          - python-packages-v1-
    - &build
      run:
        name: Build
        command: |
          python3.10 -m venv venv/
          venv/bin/pip install --no-deps --progress-bar off --upgrade -r requirements.txt
    - run:
        name: ruff lint
        command: venv/bin/ruff check jetstream
    - run:
        name: ruff format
        command: venv/bin/ruff format --check jetstream
    - run:
        name: Mypy
        command: venv/bin/mypy jetstream
    - &authenticate
      run:
        name: Authenticate to GCP
        command: |
          export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
          echo 'export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"' >> "$BASH_ENV"
          echo "$GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
    - run:
        name: PyTest
        command: venv/bin/pytest --ruff --ruff-format --ignore=jetstream/tests/integration/
    - save_cache:
        paths:
        - venv/
        key: *cache_key
  integration:
    docker:
    - image: python:3.10
    steps:
    - checkout
    - &skip_forked_pr
      run:
        name: Early return if this build is from a forked PR
        command: |
          if [ -n "$CIRCLE_PR_NUMBER" ]; then
            echo "Cannot pass creds to forked PRs, so marking this step successful"
            circleci step halt
          fi
    - &build
      run:
        name: Build
        command: |
          python3.10 -m venv venv/
          venv/bin/pip install --no-deps --progress-bar off --upgrade -r requirements.txt
    - &pytest_integration_test
      run:
        name: PyTest Integration Test
        # Google's client libraries will check for GOOGLE_APPLICATION_CREDENTIALS
        # and use a file in that location for credentials if present;
        # See https://cloud.google.com/docs/authentication/production
        command: |
          export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
          echo "$GCLOUD_SERVICE_KEY_INTEGRATION_TEST" > "$GOOGLE_APPLICATION_CREDENTIALS"
          venv/bin/pytest --ruff --ruff-format --integration jetstream/tests/integration/
  deploy:
    docker:
      - image: python:3.10
    steps:
      - checkout
      - run:
          name: Install deployment tools
          command: |
            pip install --upgrade build setuptools wheel twine
      - run:
          name: Create the distribution files
          command: |
            python -m build --sdist
      - run:
          name: Upload to PyPI
          command: |
            # Relies on the TWINE_USERNAME and TWINE_PASSWORD environment variables configured at:
            #   https://app.circleci.com/settings/project/github/mozilla/jetstream/environment-variables
            # For more on twine, see:
            #   https://twine.readthedocs.io/en/latest/
            twine upload --skip-existing dist/*

workflows:
  version: 2.1
  build-and-deploy:
    jobs:
      - build
      - integration
      - gcp-gcr/build-and-push-image:
          gcloud-service-key: EXPERIMENTS_GCLOUD_SERVICE_KEY
          requires:
            - build
            - integration
          image: jetstream
          filters:
            branches:
              only:
                main
  tagged-deploy:
    jobs:
      - deploy:
          filters:
            tags:
              only: /[0-9]{4}.[0-9]{1,2}.[0-9]+/  # Calver: YYYY.M.MINOR
            branches:
              # Ignore all branches; this workflow should only run for tags.
              ignore: /.*/
```

After migration:

```yaml
name: Jetstream Build and Deploy

on:
  push:
    branches:
      - main
    tags:
      - '[0-9][0-9][0-9][0-9].[0-9]{1,2}.[0-9]+'
  pull_request:
    branches:
      - main
  merge_group:

jobs:
  build:
    environment: GH Actions
    permissions:
      contents: read
      id-token: write
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      - name: Build venv and install dependencies
        run: |
          python3.10 -m venv venv/
          venv/bin/pip install --no-deps --progress-bar off --upgrade -r requirements.txt
      - name: Ruff lint
        run: venv/bin/ruff check jetstream
      - name: Ruff format
        run: venv/bin/ruff format --check jetstream
      - name: Mypy
        run: venv/bin/mypy jetstream
      - name: Authenticate to GCP and Generate ID Token
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_DRYRUN_SERVICE_ACCOUNT_EMAIL }}
          token_format: 'id_token'
          id_token_audience: 'https://us-central1-moz-fx-data-shared-prod.cloudfunctions.net/bigquery-etl-dryrun'
          id_token_include_email: true
      - name: Export ID Token for Python
        run: echo "GOOGLE_GHA_ID_TOKEN=${{ steps.auth.outputs.id_token }}" >> $GITHUB_ENV
      - name: PyTest
        run: venv/bin/pytest --ruff --ruff-format --ignore=jetstream/tests/integration/ -n 8

  integration:
    permissions:
      contents: read
      id-token: write
    environment: GH Actions
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Build venv and install dependencies
        run: |
          python3.10 -m venv venv/
          venv/bin/pip install --no-deps --progress-bar off --upgrade -r requirements.txt
      - name: Authenticate to GCP (OIDC)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_INTEGRATION_SERVICE_ACCOUNT_EMAIL }}
      - name: PyTest Integration Test
        run: venv/bin/pytest --ruff --ruff-format --integration jetstream/tests/integration/ -n 8

  deploy:
    permissions:
      contents: read
      id-token: write
    environment:
      name: pypi
      url: https://pypi.org/p/mozilla-jetstream
    if: startsWith(github.ref, 'refs/tags/')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install deployment tools
        run: pip install --upgrade build setuptools wheel twine
      - name: Build distribution files
        run: python -m build --sdist
      - name: Publish distribution 📦 to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1

  docker:
    permissions:
      contents: read
      id-token: write
    environment: GH Actions
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    needs: [build, integration]
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: docker build . -t jetstream:latest
      - name: Push Docker image to GAR
        uses: mozilla-it/deploy-actions/docker-push@v3
        with:
          project_id: moz-fx-data-experiments
          local_image: jetstream
          image_repo_host: gcr.io
          image_repo_path: moz-fx-data-experiments/jetstream
          workload_identity_pool_project_number: ${{ vars.GCPV2_WORKLOAD_IDENTITY_POOL_PROJECT_NUMBER }}
```

# Example 3 Successful Migration

```yaml
orbs:
  gcp-gcr: circleci/gcp-gcr@0.16.2

version: 2.1

jobs:
  test:
    docker:
      - image: cimg/base:current  # https://circleci.com/developer/images/image/cimg/base
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Build image
          command: make build
      - run:
          name: Test Code
          command: make test
      - run:
          name: Lint
          command: make lint

workflows:
  version: 2
  public-data-report-etl-build:
    jobs:
      - test:
          filters:
            tags:
              only: /.*/
      - gcp-gcr/build-and-push-image:
          context: data-eng-airflow-gcr
          image: firefox-public-data-report-etl
          filters:
            branches:
              only: main
```

After migration:

```yaml
name: Build and Deploy

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Build image
        run: make build
      - name: Test code
        run: make test
      - name: Lint
        run: make lint

  build-and-push-image:
    if: github.ref == 'refs/heads/main'
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Build the Docker image
        run: docker build . -t us-docker.pkg.dev/moz-fx-data-artifacts-prod/firefox-public-data-report-etl/firefox-public-data-report-etl:latest
      - name: Push Docker image to GAR
        uses: mozilla-it/deploy-actions/docker-push@v4.3.2
        with:
          project_id: moz-fx-data-artifacts-prod
          image_tags: us-docker.pkg.dev/moz-fx-data-artifacts-prod/firefox-public-data-report-etl/firefox-public-data-report-etl:latest
          workload_identity_pool_project_number: ${{ vars.GCPV2_WORKLOAD_IDENTITY_POOL_PROJECT_NUMBER }}
          service_account_name: github-actions-artifact-pusher
```

# Example 3 Successful Migration

```yaml
# config.yml

version: 2.1

setup: true

orbs:
  path-filtering: circleci/path-filtering@1.3.0

workflows:
  filter-paths-main:
    when:
      and:
        - equal: [main, << pipeline.git.branch >>]
    jobs:
      - path-filtering/filter:
          base-revision: << pipeline.git.base_revision >>
          config-path: .circleci/validation-config.yml
          mapping: |
            opmon/.* validate-opmon true
            jetstream/.* validate-jetstream true
            definitions/.* validate-metrics true
            looker/.* validate-looker true
            lib/metric-config-parser/.* validate-metric-config-parser true
            lib/metric-config-parser/pyproject.toml deploy-metric-config-parser true
  filter-paths-pr:
    when:
      and:
        - not:
            equal: [main, << pipeline.git.branch >>]
    jobs:
      - path-filtering/filter:
          base-revision: main
          config-path: .circleci/validation-config.yml
          mapping: |
            opmon/.* validate-opmon true
            jetstream/.* validate-jetstream true
            definitions/.* validate-metrics true
            looker/.* validate-looker true
            .* base-revision "main"
            lib/metric-config-parser/.* validate-metric-config-parser true
```


```yaml
# validation_config.yml

version: 2.1

parameters:
  validate-opmon:
    type: boolean
    default: false
  validate-jetstream:
    type: boolean
    default: false
  validate-metrics:
    type: boolean
    default: false
  validate-looker:
    type: boolean
    default: false
  base-revision:
    type: string
    default: << pipeline.git.base_revision >>
  validate-metric-config-parser:
    type: boolean
    default: false
  deploy-metric-config-parser:
    type: boolean
    default: false

executors:
  metric-config-parser-executor:
    docker:
    - image: python:3.10
    working_directory: ~/project/lib/metric-config-parser

jobs:
  validate-metrics:
    docker:
    - image: python:3.10
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - run:
        name: Build
        command: |
          pip install -r .script/requirements.txt
          pip install lib/metric-config-parser
    - &authenticate
      run:
        name: Authenticate to GCP
        command: |
          export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
          echo 'export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"' >> "$BASH_ENV"
          echo "$GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
    - run:
        name: Validate config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'definitions/*.toml' 'definitions/*.example.toml')
          echo "Run validation on changed files: "
          echo $changed_files
          python3 .script/validate.py $changed_files --config_repos='.'
  validate-opmon:
    docker:
    - image: gcr.io/moz-fx-data-experiments/opmon:latest
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - *authenticate
    - run:
        name: Validate OpMon config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'opmon/*.toml' 'opmon/*.toml.example')
          echo "Run validation on changed files: "
          echo $changed_files
          opmon validate_config --config_repos='.' --config_repos=opmon/ $changed_files
  validate-jetstream:
    docker:
    - image: gcr.io/moz-fx-data-experiments/jetstream:latest
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - *authenticate
    - run:
        name: Validate jetstream config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'jetstream/*.toml' 'jetstream/*.toml.example')
          echo "Run validation on changed files: "
          echo $changed_files
          jetstream validate_config --config_repos='.' --config_repos='jetstream/' $changed_files
  validate-looker:
    docker:
    - image: python:3.10
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - run:
        name: Build
        command: |
          pip install -r .script/requirements.txt
          pip install lib/metric-config-parser
    - *authenticate
    - run:
        name: Validate config files
        command: |
          changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'looker/*.toml' 'looker/*.example.toml')
          echo "Run validation on changed files: "
          echo $changed_files
          python3 .script/validate.py --config_repos='.' --config_repos=looker/ $changed_files
  build-metric-config-parser:
    executor: metric-config-parser-executor
    steps:
    - checkout:
        path: ~/project
    - restore_cache:
        keys:
          # when lock files change, use increasingly general patterns to restore cache
          - &cache_key
            python-packages-v2-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
          - python-packages-v2-{{ .Branch }}-{{ checksum "requirements.in" }}-
          - python-packages-v2-{{ .Branch }}-
          - python-packages-v2-
    - &build
      run:
        name: Build
        command: |
          python3.10 -m venv venv/
          venv/bin/python -m pip install --upgrade pip
          venv/bin/pip install --progress-bar off --upgrade -r requirements.txt
    - run:
        name: ruff
        command: venv/bin/ruff check metric_config_parser
    - run:
        name: ruff format
        command: venv/bin/ruff format --check metric_config_parser
    - run:
        name: Mypy
        command: venv/bin/mypy metric_config_parser
    - run:
        name: PyTest
        command: venv/bin/pytest --ruff --ignore=metric_config_parser/tests/integration/
    - save_cache:
        paths:
        - venv/
        key: *cache_key
  integration-metric-config-parser:
    executor: metric-config-parser-executor
    steps:
    - checkout:
        path: ~/project
    - *build
    - run:
        name: PyTest Integration Test
        command: |
          venv/bin/pytest --ruff metric_config_parser/tests/integration/
  rerun-jetstream:
    docker:
    - image: google/cloud-sdk
    environment:
      BASE_COMMIT: << pipeline.parameters.base-revision >>
      REVISION_COMMIT: << pipeline.git.revision >>
    steps:
    - checkout
    - &skip_forked_pr
      run:
        name: Early return if this build is from a forked PR
        command: |
          if [ -n "$CIRCLE_PR_NUMBER" ]; then
            echo "Do not re-run analysis on forked PRs, so marking this step successful"
            circleci step halt
          fi
    - run:
        name: Authorize gcloud CLI
        command: |
          # required for parsing kubectl pod statuses
          apt-get install jq -y
          apt-get install uuid-runtime
          export USE_GKE_GCLOUD_AUTH_PLUGIN=True
          export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
          echo "$JETSTREAM_GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
          gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS
          gcloud config set project $GCLOUD_PROJECT
          gcloud container clusters get-credentials jetstream --zone us-central1-a --project $GCLOUD_PROJECT
    - run:
        name: Rerun jetstream
        command: |
          echo "Skipping rerun in CircleCI, see Github Actions for this workflow."
          # changed_files=$(git diff --name-only $BASE_COMMIT..$REVISION_COMMIT -- 'jetstream/*.toml' 'jetstream/*.toml.example')

          # # determine slugs of configs that got changed; filter out outcomes and defaults
          # params=""
          # for config in $changed_files; do
          #   slug=${config##*/}
          #   slug="${slug%.*}"
          #   if [ -e jetstream/"$slug".toml ]; then
          #     params+="--experiment_slug=${slug} "
          #   fi
          # done

          # echo "Latest change affected these experiments:"
          # echo $params

          # # stop running instances so that they do not interfere
          # uuid=`uuidgen`
          # pod_identifier="jetstream-${uuid}"
          # kubectl delete pod -l app=$pod_identifier

          # commit_message=$(git log --format=oneline -n 1 $CIRCLE_SHA1)
          # if [[ "$commit_message" == *"[ci rerun-skip]"* ]] || [[ "$commit_message" == *"[ci rerun_skip]"* ]] || [[ "$commit_message" == *"[ci skip-rerun]"* ]] || [[ "$commit_message" == *"[ci skip_rerun]"* ]]; then
          #   echo "Skip rerun for files:"
          #   echo $changed_files

          #   # start a new instance
          #   kubectl run $pod_identifier --image=gcr.io/moz-fx-data-experiments/jetstream -l app=$pod_identifier --restart=Never --command -- jetstream rerun-skip $(echo $params)
          # else
          #   echo "Rerun changed files: "
          #   echo $changed_files

          #   # start a new instance
          #   kubectl run $pod_identifier --image=gcr.io/moz-fx-data-experiments/jetstream -l app=$pod_identifier --restart=Never --command -- jetstream rerun --argo --return-status --recreate-enrollments $(echo $params)
          #   # link to logs
          #   cur_date=`date -u +%FT%TZ`
          #   echo "Pod Logs: https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.project_id%3D%22moz-fx-data-experiments%22%0Aresource.labels.location%3D%22us-central1-a%22%0Aresource.labels.cluster_name%3D%22jetstream%22%0Aresource.labels.namespace_name%3D%22default%22?scrollTimestamp=$cur_date"
          #   echo "Analysis Errors can be accessed via Redash: https://sql.telemetry.mozilla.org/dashboard/jetstream-errors?p_experiment=%25"
          #   # wait for pod to finish and check status
          # fi

          # running=true
          # while [ $running = true ]
          # do
          #   echo "Wait for jetstream to finish"
          #   pod_status=`kubectl get pod -l app=$pod_identifier --no-headers -o custom-columns=":status.phase"`
          #   if [ $pod_status = 'Succeeded' ] || [ $pod_status = 'Failed' ]; then
          #     running=false
          #   fi
          #   sleep 10
          # done
          # # delete pod
          # kubectl delete pod -l app=$pod_identifier
          # if [ $pod_status = 'Failed' ]; then
          #   echo "Error when running jetstream. Check the logs for more information."
          #   exit 1
          # elif [ $pod_status = 'Succeeded' ]; then
          #   echo "Jetstream successfully completed."
          # else
          #   echo "Jetstream completed in unknown status. Please check the logs."
          #   echo "Analysis Errors can be accessed via Redash: https://sql.telemetry.mozilla.org/dashboard/jetstream-errors?p_experiment=%25"
          #   exit 1
          # fi
  deploy-metric-config-parser:
    executor: metric-config-parser-executor
    steps:
      - checkout:
          path: ~/project
      - run:
          name: Check for package version change in last commit before proceeding.
          command: |
            if git diff main HEAD~1 pyproject.toml | grep 'version'
              then
                echo "Found changes to package version dir, proceeding with deployment."
              else
                echo "No changes in package version. Skipping metric-config-parser deployment."
                circleci-agent step halt
            fi
      - run:
          name: Install deployment tools
          command: |
            pip install --upgrade build setuptools wheel twine
      - run:
          name: Create the distribution files
          command: |
            python3.10 -m build --sdist
      - run:
          name: Upload to PyPI
          command: |
            # Relies on the TWINE_USERNAME and TWINE_PASSWORD environment variables configured at:
            #   https://circleci.com/gh/mozilla/metric-config-parser/edit#env-vars
            # For more on twine, see:
            #   https://twine.readthedocs.io/en/latest/
            twine upload --skip-existing dist/*
  nothing-to-do:
    executor: metric-config-parser-executor
    steps:
      - run:
          name: Placeholder job to prevent CircleCI error about no workflows to run.
          command: |
            echo "Does nothing, see https://github.com/CircleCI-Public/circleci-cli/issues/577"

workflows:
  version: 2
  validate-metrics:
    when: 
      or: 
        - << pipeline.parameters.validate-metrics >>
    jobs:
      - validate-metrics
  validate-opmon:
    when: 
      or: 
        - << pipeline.parameters.validate-opmon >>
    jobs:
      - validate-opmon
  validate-jetstream:
    when: 
      or: 
        - << pipeline.parameters.validate-jetstream >>
    jobs:
      - validate-jetstream
  validate-looker:
    when: 
      or: 
        - << pipeline.parameters.validate-looker >>
    jobs:
      - validate-looker
  build-metric-config-parser:
    when: 
      or: 
        - << pipeline.parameters.validate-metric-config-parser >>
    jobs:
      - build-metric-config-parser
  integration-metric-config-parser:
    when: 
      or: 
        - << pipeline.parameters.validate-metric-config-parser >>
    jobs:
      - integration-metric-config-parser
  deploy-metric-config-parser:
    when: 
      or: 
        - << pipeline.parameters.deploy-metric-config-parser >>
    jobs:
      - deploy-metric-config-parser
  rerun-jetstream:
    when: 
      or: 
        - << pipeline.parameters.validate-jetstream >>
    jobs:
      - rerun-jetstream:
          filters:
            branches:
              only: main
  nothing-to-do:
    jobs:
      - nothing-to-do
```

After migration:

```yaml
# auto_approve.yml

name: "Auto approve"
on:
  pull_request:
    branches:
      - main

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        definitions/*.toml
        lib/
        .github/
        .circleci/

  approve:
    name: Auto approve PR if no metrics definitions changed
    permissions:
      pull-requests: write
    runs-on: ubuntu-latest 
    needs: changed
    steps:
    - uses: actions/github-script@v6
      if: needs.changed.outputs.any_changed == 'false'
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          github.rest.pulls.createReview({
            owner: context.repo.owner,
            repo: context.repo.repo,
            pull_number: context.issue.number,
            event: "APPROVE"
          })
    - name: Skip
      if: needs.changed.outputs.any_changed == 'true'
      env:
        ALL_CHANGED_FILES: ${{ needs.changed.outputs.all_changed_files }}
      run: |
        echo "Metric definitions changed, needs manual review"
        echo "Changed files: $ALL_CHANGED_FILES"
```

```yaml
# build-docs.yml

name: "Build docs"

on:
  push:
    branches:
      - main

jobs:
  build-docs:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: Install dependencies
      run: |
        python3.10 -m venv venv/
        venv/bin/python -m pip install -r .script/requirements.txt
        venv/bin/python -m pip install lib/metric-config-parser
    - name: Build docs
      run: |
        venv/bin/python .script/generate_docs.py \
          --output_dir=generated_docs/
        cd generated_docs/
        PATH="../venv/bin:$PATH" mkdocs gh-deploy --force \
          -m "[ci skip] Deployed {sha} with MkDocs version: {version}"
```

```yaml
# changed-files.yml

name: Get changed files

on:
  workflow_call:
    inputs:
      path_filter:
        type: string
        description: 'Path filter to look for changed files'
        required: false
        default: '**'
    outputs:
      any_changed:
        description: 'Did any file matching optional path filter change? [true|false]'
        value: ${{ jobs.changed.outputs.any_changed }}
      all_changed_files:
        description: 'List of changed files matching optional path filter'
        value: ${{ jobs.changed.outputs.all_changed_files }}

jobs:
  changed:
    runs-on: ubuntu-latest 
    name: Get changed files
    outputs:
      any_changed: ${{ steps.changed-files-specific.outputs.any_changed }}
      all_changed_files: ${{ steps.changed-files-specific.outputs.all_changed_files }}
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    - name: Get changed files
      id: changed-files-specific
      uses: tj-actions/changed-files@24d32ffd492484c1d75e0c0b894501ddb9d30d62
      with:
        files: ${{ inputs.path_filter }}
    - name: Print results
      env:
        PATH_FILTER: ${{ inputs.path_filter }}
        ANY_CHANGED: ${{ steps.changed-files-specific.outputs.any_changed }}
        ALL_CHANGED_FILES: ${{ steps.changed-files-specific.outputs.all_changed_files }}
      run: |
        echo "Using path filter: $PATH_FILTER"
        echo "Did files change?: $ANY_CHANGED"
        echo "All changed files: $ALL_CHANGED_FILES"
```

```yaml
# deploy-metric-config-parser.yml

# This workflow is based on the GH Actions docs on publishing python artifacts:
# https://docs.github.com/en/actions/tutorials/build-and-test-code/python#publishing-to-package-registries

name: "Deploy metric-config-parser"

on:
  push:
    branches:
      - main
    paths:
      - 'lib/metric-config-parser/pyproject.toml'

permissions:
  contents: read

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        lib/metric-config-parser/pyproject.toml

  check-version-change:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      contents: read
    outputs:
      proceed: ${{ steps.version_change.outputs.proceed }}
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v5
      with:
        fetch-depth: 0
    - id: version_change
      name: Check for package version change in last commit before proceeding.
      run: |
        if git diff origin/main HEAD~1 -- ./lib/metric-config-parser/pyproject.toml | grep '\+version'
          then
            echo "Found changes to package version dir, proceeding with deployment."
            echo "proceed=true" >> "GITHUB_OUTPUT"
          else
            echo "No changes in package version. Skipping metric-config-parser deployment."
            echo "proceed=false" >> "GITHUB_OUTPUT"
        fi

  build-metric-config-parser:
    runs-on: ubuntu-latest
    needs: check-version-change
    permissions:
      contents: read
    if: needs.check-version-change.outputs.proceed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v5
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: Install deployment tools
      working-directory: ./lib/metric-config-parser
      run: |
        python3 -m pip install --upgrade pip build setuptools wheel
    - name: Create the distribution files
      working-directory: ./lib/metric-config-parser
      run: |
        python3.10 -m build --sdist
    - name: Upload distribution
      uses: actions/upload-artifact@v4
      with:
        name: release-dist
        path: ./lib/metric-config-parser/dist

  deploy-metric-config-parser:
    runs-on: ubuntu-latest
    needs: build-metric-config-parser
    permissions:
      id-token: write
      contents: read
    environment:
      name: pypi
    steps:
    - name: Retrieve release distribution
      uses: actions/download-artifact@v4
      with:
        name: release-dist
        path: dist/
    - name: Publish to PyPi
      uses: pypa/gh-action-pypi-publish@release/v1
```

```yaml
# rerun-jetstream.yml

name: "Rerun jetstream"

on:
  push:
    branches:
      - main
    paths:
      - 'jetstream/**'

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        jetstream/**

  rerun-jetstream:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      contents: read
      id-token: write
    if: needs.changed.outputs.any_changed == 'true'
    env:
      CLUSTER_NAME: 'jetstream-dev'
      CLUSTER_ZONE: 'us-central1-c'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Authenticate to GCP
      uses: google-github-actions/auth@v2
      id: google_auth
      with:
        workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
        service_account: ${{ secrets.GCP_JETSTREAM_SERVICE_ACCOUNT_EMAIL }}
        project_id: ${{ vars.GCLOUD_PROJECT }}
        access_token_lifetime: 43200s
    - name: Set up GKE
      uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.CLUSTER_ZONE }}
    - name: Rerun jetstream
      shell: bash
      env:
        changed_files: ${{ needs.changed.outputs.all_changed_files }}
        commit_message: ${{ github.event.head_commit.message }}
      run: |
        changed_files="${{ needs.changed.outputs.all_changed_files }}"

        ERROR_DASHBOARD_URL="https://mozilla.cloud.looker.com/dashboards/246"

        # determine slugs of configs that got changed; filter out outcomes and defaults
        params=""
        for config in $changed_files; do
          slug=${config##*/}
          slug="${slug%.*}"
          if [ -e jetstream/"$slug".toml ]; then
            params+="--experiment_slug=${slug} "
          fi
        done

        echo "Latest change affected these experiments:"
        echo $params

        # stop running instances so that they do not interfere
        uuid=`uuidgen`
        pod_identifier="jetstream-${uuid}"
        echo "Deleting pod [$pod_identifier]"
        echo
        kubectl delete pod -l app=$pod_identifier

        cur_date=`date -u +%FT%TZ`
        LOGS_URL="https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.cluster_name%3D%22${{ env.CLUSTER_NAME }}%22%0Aresource.labels.location%3D%22${{ env.CLUSTER_ZONE }}%22%0Aresource.labels.namespace_name%3D%22argo%22;cursorTimestamp=$curDate?project=${{ vars.GCLOUD_PROJECT }}"

        commit_message="${{ github.event.head_commit.message }}"
        echo "Checking commit message: $commit_message"
        if [[ "$commit_message" == *"[ci rerun-skip]"* ]] || [[ "$commit_message" == *"[ci rerun_skip]"* ]] || [[ "$commit_message" == *"[ci skip-rerun]"* ]] || [[ "$commit_message" == *"[ci skip_rerun]"* ]]; then
          echo "Skip rerun for files:"
          echo $changed_files

          echo "[$(date +%FT%T%Z)] Running command: 'jetstream rerun-skip $params'"

          # start a new instance
          kubectl run $pod_identifier --image=gcr.io/${{ vars.GCLOUD_PROJECT }}/jetstream -l app=$pod_identifier --restart=Never --command -- jetstream rerun-skip $params
        else
          echo "Rerun changed files: "
          echo $changed_files

          echo "[$(date +%FT%T%Z)] Running command: 'jetstream rerun --argo --return-status --recreate-enrollments $params'"

          # start a new instance
          kubectl run $pod_identifier --image=gcr.io/${{ vars.GCLOUD_PROJECT }}/jetstream -l app=$pod_identifier --restart=Never --command -- jetstream rerun --argo --return-status --recreate-enrollments $params
          
          # link to logs
          echo "Pod Logs: $LOGS_URL"
          echo "Analysis Errors can be accessed via Looker: $ERROR_DASHBOARD_URL"
          # wait for pod to finish and check status
        fi

        running=true
        while [ $running = true ]
        do
          echo "[$(date +%FT%T%Z)] Wait for jetstream to finish"
          pod_status=`kubectl get pod -l app=$pod_identifier --no-headers -o custom-columns=":status.phase"`
          if [ $pod_status = 'Succeeded' ] || [ $pod_status = 'Failed' ]; then
            running=false
          fi
          sleep 10
        done
        # delete pod
        echo "Deleting pod [$pod_identifier]"
        echo
        kubectl delete pod -l app=$pod_identifier
        if [ $pod_status = 'Failed' ]; then
          echo "[$(date +%FT%T%Z)] Error when running jetstream. Check the pod logs or error dashboard for more information."
          echo "Pod Logs: $LOGS_URL"
          echo "Analysis Errors dashboard: $ERROR_DASHBOARD_URL"
          exit 1
        elif [ $pod_status = 'Succeeded' ]; then
          echo "[$(date +%FT%T%Z)] Jetstream successfully completed."
        else
          echo "[$(date +%FT%T%Z)] Jetstream completed in unknown status. Please check the pod logs or error dashboard."
          echo "Pod Logs: $LOGS_URL"
          echo "Analysis Errors dashboard: $ERROR_DASHBOARD_URL"
          exit 1
        fi
```

```yaml
# rerun-skip-comment.yml

name: "rerun-skip comment"
on:
  pull_request:
    branches:
      - main

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        jetstream/defaults/*.toml

  rerun_skip_comment:
    name: Leave a comment if defaults have been changed
    permissions:
      pull-requests: write
    runs-on: ubuntu-latest 
    needs: changed
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - uses: actions/github-script@v6
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: "⚠️ Changing default metrics will cause all experiments that are currently live to get rerun after this change has been merged. This may come with a substantial cost. To skip reruns, add `[ci skip-rerun]` to the PR message."
          })
```

```yaml
# trigger-looker-dag.yml

name: "Trigger Looker DAG"

on:
  push:
    branches:
      - main
    paths:
      - 'definitions/**'
      - 'looker/**'

jobs:
  looker-deploy:
    name: Deploy Looker via Airflow DAG
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}
          project_id: ${{ vars.GCLOUD_PROJECT }}
          token_format: id_token
          id_token_audience: https://us-west1-moz-fx-telemetry-airflow-prod.cloudfunctions.net/ci-external-trigger
          id_token_include_email: true
          create_credentials_file: false

      - name: Prepare DAG run note
        run: |
          echo "DAGRUN_NOTE=DAG triggered by **[${{ github.actor }}](https://github.com/${{ github.actor }})** from ${{ github.repository }} CI build [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_ENV

      - name: Trigger looker DAG in Airflow to deploy lookml
        env:
          ID_TOKEN: ${{ steps.auth.outputs.id_token }}
        run: |
          curl --location --request POST "https://us-west1-moz-fx-telemetry-airflow-prod.cloudfunctions.net/ci-external-trigger" \
            -H "Authorization: bearer $ID_TOKEN" \
            -H "Content-Type: application/json" \
            -d "{\"dagrun_note\": \"${DAGRUN_NOTE}\", \"dag_id\":\"looker\"}"
```

```yaml
# validate-jetstream.yml

name: "Validate jetstream"

on:
  pull_request:
    branches:
      - main
    paths:
      - 'jetstream/**'
  push:
    branches:
      - main
    paths:
      - 'jetstream/**'

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        jetstream/**/*.toml
        jetstream/**/*.toml.example

  validate-jetstream:
    runs-on: ubuntu-latest
    container:
      image: gcr.io/moz-fx-data-experiments/jetstream:latest
    needs: changed
    permissions:
      contents: read
      id-token: write
      pull-requests: write
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        ref: ${{ github.head_ref }}
    - name: Set safe directory
      # workaround because actions/checkout's `set-safe-directory` flag doesn't work in containers
      # this and `ref` above are needed because jetstream performs git operations
      run: git config --global --add safe.directory "$GITHUB_WORKSPACE"
    - name: Authenticate to GCP
      uses: google-github-actions/auth@v2
      id: auth
      with:
        workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
        service_account: ${{ secrets.GCP_DRYRUN_SERVICE_ACCOUNT_EMAIL }}
        token_format: id_token
        id_token_audience: https://us-central1-moz-fx-data-shared-prod.cloudfunctions.net/bigquery-etl-dryrun
        id_token_include_email: true
    - name: Export ID Token for Python
      env:
        GOOGLE_GHA_ID_TOKEN: ${{ steps.auth.outputs.id_token }}
      run: echo "GOOGLE_GHA_ID_TOKEN=$GOOGLE_GHA_ID_TOKEN" >> $GITHUB_ENV
    - name: Validate jetstream config files
      env:
        ALL_CHANGED_FILES: ${{ needs.changed.outputs.all_changed_files }}
      run: |
        echo "Run validation on changed files: "
        echo $ALL_CHANGED_FILES
        echo "jetstream validate_config --config_repos='.' --config_repos=jetstream/ $ALL_CHANGED_FILES"
        jetstream validate_config --config_repos='.' --config_repos=jetstream/ $ALL_CHANGED_FILES
    - uses: actions/github-script@v6
      if: ${{ github.event_name == 'pull_request' && success() }}
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: "✅ Jetstream Validation is complete. Check the CI logs for this step for **Query SQL** and **data processing estimates**."
          })
```

```yaml
# validate-looker.yml

name: "Validate Looker"

on:
  pull_request:
    branches:
      - main
    paths:
      - 'looker/**'
  push:
    branches:
      - main
    paths:
      - 'looker/**'

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        looker/**/*.toml
        looker/**/*.toml.example

  validate-looker:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      id-token: write
      contents: read
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        ref: ${{ github.head_ref }}
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: Build
      run: |
        python3 -m pip install -r .script/requirements.txt
        python3 -m pip install lib/metric-config-parser
    - name: Authenticate to GCP
      uses: google-github-actions/auth@v2
      id: auth
      with:
        workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
        service_account: ${{ secrets.GCP_DRYRUN_SERVICE_ACCOUNT_EMAIL }}
        token_format: id_token
        id_token_audience: https://us-central1-moz-fx-data-shared-prod.cloudfunctions.net/bigquery-etl-dryrun
        id_token_include_email: true
    - name: Export ID Token for Python
      env:
        GOOGLE_GHA_ID_TOKEN: ${{ steps.auth.outputs.id_token }}
      run: echo "GOOGLE_GHA_ID_TOKEN=$GOOGLE_GHA_ID_TOKEN" >> $GITHUB_ENV
    - name: Validate Looker config files
      env:
        ALL_CHANGED_FILES: ${{ needs.changed.outputs.all_changed_files }}
      run: |
        echo "Run validation on changed files: "
        echo $ALL_CHANGED_FILES
        python3 .script/validate.py --config_repos='.' --config_repos=looker/ $ALL_CHANGED_FILES
```

```yaml
# validate-metric-config-parser.yml

name: "Validate metric-config-parser"

on:
  pull_request:
    branches:
      - main
    paths:
      - 'lib/metric-config-parser/**'
  push:
    branches:
      - main
      - gh-actions-migration
    paths:
      - 'lib/metric-config-parser/**'

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        lib/metric-config-parser/**

  build-metric-config-parser:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      contents: read
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Changed Files tests
      run: echo ${{ needs.changed.outputs.any_changed }} && echo ${{ needs.changed.outputs.all_changed_files }}
    - name: Checkout
      uses: actions/checkout@v4
      with:
        path: ~/project
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: restore_cache
      uses: actions/cache@v3
      with:
        key: python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
        path: venv/
        # when lock files change, use increasingly general patterns to restore cache
        restore-keys: |-
          python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
          python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-
          python-packages-v1-{{ .Branch }}-
          python-packages-v1-
    - name: Build
      working-directory: ~/project/lib/metric-config-parser
      run: |
        python3.10 -m venv venv/
        venv/bin/python -m pip install --upgrade pip
        venv/bin/pip install --progress-bar off --upgrade -r requirements.txt
    - name: Ruff check
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/ruff check metric_config_parser
    - name: Ruff format
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/ruff format --check metric_config_parser
    - name: Mypy
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/mypy metric_config_parser
    - name: PyTest
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/pytest --ruff --ignore=metric_config_parser/tests/integration/

  integration-metric-config-parser:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      contents: read
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        path: ~/project
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: Build
      working-directory: ~/project/lib/metric-config-parser
      run: |
        python3.10 -m venv venv/
        venv/bin/python -m pip install --upgrade pip
        venv/bin/pip install --progress-bar off --upgrade -r requirements.txt
    - name: PyTest Integration Test
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/pytest --ruff metric_config_parser/tests/integration/
```

```yaml
# validate-metric-config-parser.yml

name: "Validate metric-config-parser"

on:
  pull_request:
    branches:
      - main
    paths:
      - 'lib/metric-config-parser/**'
  push:
    branches:
      - main
      - gh-actions-migration
    paths:
      - 'lib/metric-config-parser/**'

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        lib/metric-config-parser/**

  build-metric-config-parser:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      contents: read
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Changed Files tests
      run: echo ${{ needs.changed.outputs.any_changed }} && echo ${{ needs.changed.outputs.all_changed_files }}
    - name: Checkout
      uses: actions/checkout@v4
      with:
        path: ~/project
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: restore_cache
      uses: actions/cache@v3
      with:
        key: python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
        path: venv/
        # when lock files change, use increasingly general patterns to restore cache
        restore-keys: |-
          python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
          python-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-
          python-packages-v1-{{ .Branch }}-
          python-packages-v1-
    - name: Build
      working-directory: ~/project/lib/metric-config-parser
      run: |
        python3.10 -m venv venv/
        venv/bin/python -m pip install --upgrade pip
        venv/bin/pip install --progress-bar off --upgrade -r requirements.txt
    - name: Ruff check
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/ruff check metric_config_parser
    - name: Ruff format
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/ruff format --check metric_config_parser
    - name: Mypy
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/mypy metric_config_parser
    - name: PyTest
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/pytest --ruff --ignore=metric_config_parser/tests/integration/

  integration-metric-config-parser:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      contents: read
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        path: ~/project
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: Build
      working-directory: ~/project/lib/metric-config-parser
      run: |
        python3.10 -m venv venv/
        venv/bin/python -m pip install --upgrade pip
        venv/bin/pip install --progress-bar off --upgrade -r requirements.txt
    - name: PyTest Integration Test
      working-directory: ~/project/lib/metric-config-parser
      run: venv/bin/pytest --ruff metric_config_parser/tests/integration/
```

```yaml
# validate-metrics.yml

name: "Validate Metrics"

on:
  pull_request:
    branches:
      - main
    paths:
      - 'definitions/**'
  push:
    branches:
      - main
    paths:
      - 'definitions/**'

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        definitions/*.toml
        definitions/*.toml.example

  validate-metrics:
    runs-on: ubuntu-latest
    needs: changed
    permissions:
      id-token: write
      contents: read
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        ref: ${{ github.head_ref }}
    - name: Setup python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"
        cache: 'pip'
    - name: Build
      run: |
        python3 -m pip install -r .script/requirements.txt
        python3 -m pip install lib/metric-config-parser
    - name: Authenticate to GCP
      uses: google-github-actions/auth@v2
      id: auth
      with:
        workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
        service_account: ${{ secrets.GCP_DRYRUN_SERVICE_ACCOUNT_EMAIL }}
        token_format: id_token
        id_token_audience: https://us-central1-moz-fx-data-shared-prod.cloudfunctions.net/bigquery-etl-dryrun
        id_token_include_email: true
    - name: Export ID Token for Python
      env:
        GOOGLE_GHA_ID_TOKEN: ${{ steps.auth.outputs.id_token }}
      run: echo "GOOGLE_GHA_ID_TOKEN=$GOOGLE_GHA_ID_TOKEN" >> $GITHUB_ENV
    - name: Validate metric config files
      env:
        ALL_CHANGED_FILES: ${{ needs.changed.outputs.all_changed_files }}
      run: |
        echo "Run validation on changed files: "
        echo $ALL_CHANGED_FILES
        python3 .script/validate.py --config_repos='.' $ALL_CHANGED_FILES
```

```yaml
# validate-opmon.yml

name: "Validate OpMon"

on:
  pull_request:
    branches:
      - main
    paths:
      - 'opmon/**'
  push:
    branches:
      - main
    paths:
      - 'opmon/**'

jobs:
  changed:
    uses: ./.github/workflows/changed-files.yml
    with:
      path_filter: |
        opmon/**/*.toml
        opmon/**/*.toml.example

  validate-opmon:
    runs-on: ubuntu-latest
    container:
      image: gcr.io/moz-fx-data-experiments/opmon:latest
    needs: changed
    if: needs.changed.outputs.any_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Validate OpMon config files
      env:
        ALL_CHANGED_FILES: ${{ needs.changed.outputs.all_changed_files }}
      run: |
        echo "Run validation on changed files: "
        echo $ALL_CHANGED_FILES
        opmon validate_config --config_repos='.' --config_repos=opmon/ $ALL_CHANGED_FILES
```

# Example 4

```yaml
####################
# CircleCI configuration reference:
#   https://circleci.com/docs/2.0/configuration-reference
####################
# CircleCI built-in environment variables:
#   https://circleci.com/docs/2.0/env-vars/#built-in-environment-variables
####################

test_settings: &test_settings
  steps:
    - checkout
    - run: &run_tox_environment_matching_circleci_job_name
        name: Run tox job
        command: |
          pip install tox
          tox -e $CIRCLE_JOB
    - run:
        name: Submit code coverage data
        command: |
          curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --no-default-keyring --keyring trustedkeys.gpg --import
          curl -Os https://uploader.codecov.io/latest/linux/codecov
          curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM
          curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM.sig
          gpgv codecov.SHA256SUM.sig codecov.SHA256SUM
          shasum -a 256 -c codecov.SHA256SUM
          chmod +x codecov
          ./codecov -F "$(basename $PWD | sed s/[^a-z]/_/g)"

####################
# Jobs: see https://circleci.com/docs/2.0/jobs-steps/
####################

version: 2
jobs:
  py310:
    <<: *test_settings
    docker:
      - image: cimg/python:3.10

  lint:
    docker:
      - image: cimg/python:3.10
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            pip install -r requirements-dev.txt
      - run:
          name: Run linting
          command: |
            ruff check src/ tests/
            ruff format --check src/ tests/
      - run:
          name: MyPy
          command: |
            mypy src/

  # Runs when the repository is tagged for release; see the workflows section
  # below for trigger logic.
  deploy:
    docker:
      - image: cimg/python:3.10
    steps:
      - checkout
      - run:
          name: Install deployment tools
          command: |
            pip install -r requirements-dev.txt
      - run:
          name: Create the distribution files
          command: |
            python3 -m build --sdist
      - run:
          name: Upload to PyPI
          command: |
            # Relies on the TWINE_USERNAME and TWINE_PASSWORD environment variables configured at:
            #   https://circleci.com/gh/mozilla/mozanalysis/edit#env-vars
            # For more on twine, see:
            #   https://twine.readthedocs.io/en/latest/
            twine upload dist/*

  docs: &docs_settings
    docker:
      - image: cimg/python:3.10
    steps:
      - checkout
      - run:
          <<: *run_tox_environment_matching_circleci_job_name
      - persist_to_workspace:
          root: docs/_build
          paths: html

  docs-deploy:
    docker:
      - image: node:22
    steps:
      - checkout
      - attach_workspace:
          at: docs/_build
      - run:
          name: Disable jekyll builds
          command: touch docs/_build/html/.nojekyll
      # Needed for write access to the GitHub repository;
      # see https://circleci.com/docs/2.0/gh-bb-integration/#deployment-keys-and-user-keys
      - add_ssh_keys:
          fingerprints: "1d:46:d1:24:12:32:22:1c:2a:6e:c0:82:72:ab:00:31"
      # The gh-pages npm package looks to be the most widely used utility for
      # pushing a directory to a git branch;
      # see https://www.npmjs.com/package/gh-pages
      - run:
          name: Deploy docs to gh-pages branch
          command: |
            git config user.email "fx-data-platform@mozilla.com"
            git config user.name "CircleCI docs-deploy job"
            npm install -g --silent gh-pages@^2.0.0
            gh-pages --dotfiles --message "[skip ci] Updates" --dist docs/_build/html

####################
# Workflows: see https://circleci.com/docs/2.0/workflows/
####################

workflows:
  version: 2
  build:
    jobs:
      - py310
      - lint
      - docs
      - docs-deploy:
          requires:
            - docs
          filters:
            branches:
              only: main
  tagged-deploy:
    jobs:
      - deploy:
          filters:
            tags:
              only: /[0-9]{4}.[0-9]{1,2}.[0-9]+/ # Calver: YYYY.M.MINOR
            branches:
              # Ignore all branches; this workflow should only run for tags.
              ignore: /.*/
```

After migration

```yaml
# build.yml

name: Build, Test, and Deploy
on:
  push:
    branches:
  pull_request:

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      - name: Install dependencies
        run: pip install -r requirements-dev.txt
      - name: Run linting
        run: |
          ruff check src/ tests/
          ruff format --check src/ tests/
      - name: MyPy
        run: mypy src/

  py310:
    name: Test (Python 3.10)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      - name: Run tox job
        run: |
          pip install tox
          tox -e py310
      - name: Submit code coverage data
        run: |
          curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --no-default-keyring --keyring trustedkeys.gpg --import
          curl -Os https://uploader.codecov.io/latest/linux/codecov
          curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM
          curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM.sig
          gpgv codecov.SHA256SUM.sig codecov.SHA256SUM
          shasum -a 256 -c codecov.SHA256SUM
          chmod +x codecov
          ./codecov -F "$(basename $PWD | sed s/[^a-z]/_/g)"

  docs:
    name: Build Docs
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      - name: Run tox job
        run: |
          pip install tox
          tox -e docs
      - name: Upload docs artifact
        uses: actions/upload-artifact@v4
        with:
          name: docs-html
          path: docs/_build/html

  docs-deploy:
    needs: docs
    runs-on: ubuntu-latest
    permissions:
      contents: write
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - uses: actions/download-artifact@v4
        with:
          name: docs-html
          path: docs/_build/html
      - name: Disable jekyll builds
        run: touch docs/_build/html/.nojekyll
      - name: Deploy docs to gh-pages branch
        run: |
          git config user.email "fx-data-platform@mozilla.com"
          git config user.name "GitHub Actions docs-deploy job"
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
          npm install -g --silent gh-pages@^2.0.0
          gh-pages --dotfiles --message "[skip ci] Updates" --dist docs/_build/html
```

```yaml
# tagged-deploy.yml

name: Tagged Deploy

on:
  push:
    tags:
      - '[0-9][0-9][0-9][0-9].[0-9]{1,2}.[0-9]+' # Calver: YYYY.M.MINOR

jobs:
  deploy:
    name: Deploy to PyPI
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    environment:
      name: pypi
      url: https://pypi.org/p/mozanalysis
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install build dependencies
        run: python -m pip install --upgrade build

      - name: Create the distribution files
        run: python -m build --sdist

      - name: Publish distribution to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
```

# Example lookml-generator

```yaml
---
version: 2.1

# See https://circleci.com/orbs/registry/orb/circleci/gcp-gcr
orbs:
  gcp-gcr: circleci/gcp-gcr@0.16.2
  docker: circleci/docker@2.5.0
  python: circleci/python@2.1.1
  gcp-cli: circleci/gcp-cli@3.1.1

executors:
  ubuntu-machine-executor:
    machine:
      image: ubuntu-2404:current

parameters:
  python-version:
    type: string
    default: '3.10'

jobs:
  unit-tests:
    docker: &docker
      - image: python:<< pipeline.parameters.python-version >>
    steps:
      - checkout
      - &restore_cache
        restore_cache:
          keys:
            # when lock files change, use increasingly general
            # patterns to restore cache
            - &cache_key # yamllint disable-line rule:line-length
              python-<< pipeline.parameters.python-version >>-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
              # yamllint disable-line rule:line-length
            - python-<< pipeline.parameters.python-version >>-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-
            - python-<< pipeline.parameters.python-version >>-packages-v1-{{ .Branch }}-
            - python-<< pipeline.parameters.python-version >>-packages-v1-master-
            - python-<< pipeline.parameters.python-version >>-packages-v1-
      - &build
        run:
          name: Build
          command: |
            python -m venv venv/
            venv/bin/pip install pip-tools --constraint requirements.in
            venv/bin/pip-sync
      - run:
          name: PyTest with linters
          command: venv/bin/pytest
      - run:
          name: Flake8
          command: venv/bin/flake8 generator
      - run:
          name: Lint YAML
          command: venv/bin/yamllint -c .yamllint.yaml .
      - save_cache:
          paths:
            - venv/
          key: *cache_key
  verify-requirements:
    docker: *docker
    steps:
      - checkout
      - run:
          name: Verify that requirements.txt contains the right dependencies for
            this python version
          # use `--constraint` with `requirements.in` not `requirements.txt`
          # because for pip>=20.3 "Constraints are only allowed to take the form
          # of a package name and a version specifier"
          command: |
            pip install pip-tools --constraint requirements.in
            pip-compile --allow-unsafe --generate-hashes --quiet
            git diff --exit-code -G '^ *[^# ]' -- requirements.txt
  integration-tests:
    docker: *docker
    steps:
      - checkout
      - &skip_forked_pr
        run:
          name: Early return if this build is from a forked PR
          command: |
            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              echo "Cannot pass creds to forked PRs," \
                "so marking this step successful"
              circleci step halt
            fi
      - *restore_cache
      - *build
      - run:
          name: PyTest Integration Test
          # Google's client libraries will check for
          # GOOGLE_APPLICATION_CREDENTIALS
          # and use a file in that location for credentials if present;
          # See https://cloud.google.com/docs/authentication/production
          command: |
            export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
            echo "$GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
            venv/bin/pytest -m integration
  docs-build:
    docker: *docker
    steps:
      - checkout
      - *build
      - run:
          name: Build docs
          command: |
            venv/bin/pip install pdoc
            venv/bin/pdoc -o /tmp/_html generator
      - persist_to_workspace:
          root: /tmp
          paths: _html
  generate-lookml:
    docker: *docker
    steps: 
      - checkout
      - *skip_forked_pr
      - *restore_cache
      - *build
      - &attach_generated_lookml
        attach_workspace:
          at: /tmp/workspace
      - run:
          name: Authenticate to GCP
          command: |
            export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
            echo 'export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"' >> "$BASH_ENV"
            echo "$GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
      - run:
          name: Generate LookML
          command: |
            ./bin/generator namespaces
            cat namespaces.yaml
            ./bin/generator lookml --target-dir=/tmp/workspace/generated-lookml --use_cloud_function=True
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - generated-lookml
  generate-diff:
    docker:
      - image: cimg/node:21.2.0
    steps:
      - checkout
      - *skip_forked_pr
      - *attach_generated_lookml
      - add_ssh_keys:
          fingerprints:
            - "f6:e8:0c:dd:e4:16:0c:4f:1a:5d:da:56:82:9e:a3:61"
      - run:
          name: Pull in looker-hub
          command: |
            git clone --branch main https://github.com/mozilla/looker-hub.git /tmp/workspace/looker-hub
      - run:
          name: Generate diff
          command: |
            # remove empty directories as they are not checked into looker-hub
            find /tmp/workspace/generated-lookml -type d -empty -delete

            # operational monitoring artifacts cannot be generated, copy from looker-hub so
            # they don't show up as missing.
            # todo: update operational monitoring logic so BigQuery access is not needed
            cp -R /tmp/workspace/looker-hub/operational_monitoring /tmp/workspace/generated-lookml
            yq eval -i 'del(.operational_monitoring)' /tmp/workspace/generated-lookml/namespaces.yaml
            yq eval -i 'del(.operational_monitoring)' /tmp/workspace/looker-hub/namespaces.yaml

            # the following files are only in looker-hub/ (manually checked in) and can be ignored
            rm /tmp/workspace/looker-hub/README.md
            rm /tmp/workspace/looker-hub/hub.model.lkml
            rm /tmp/workspace/looker-hub/CODE_OF_CONDUCT.md
            rm /tmp/workspace/looker-hub/firefox_ios/views/column_field_paths.view.lkml

            diff -x '.*' -qr --no-dereference \
              /tmp/workspace/looker-hub/ /tmp/workspace/generated-lookml/ \
              | grep '^Only in' \
              >> /tmp/workspace/lookml.diff || true
            diff -x '.*' -bur --no-dereference --new-file \
              /tmp/workspace/looker-hub/ /tmp/workspace/generated-lookml/ \
              >> /tmp/workspace/lookml.diff || true
      - store_artifacts:
          path: /tmp/workspace/lookml.diff
          destination: lookml.diff
      - run: npm i circle-github-bot@2.1.0 @octokit/graphql@7.0.2
      - run: .circleci/post-diff.js
  docs-deploy:
    docker:
      - image: node:14
    steps:
      - checkout
      - attach_workspace:
          at: /tmp
      - run:
          name: Install and configure dependencies
          command: |
            npm install -g --silent gh-pages@3.0.0
            git config user.email "ci-build-docs@mozilla.com"
            git config user.name "ci-build-docs"
      - add_ssh_keys:
          fingerprints:
            - "f6:e8:0c:dd:e4:16:0c:4f:1a:5d:da:56:82:9e:a3:61"
      - run:
          name: Deploy docs to gh-pages branch
          command: gh-pages --message "[skip ci] updates" --dist /tmp/_html
  looker-deploy:
    executor: gcp-cli/google
    steps:
      - run:
          name: Prepare environment variables for OIDC authentication
          # Project ID is not used for OIDC authentication, but gcloud CLI requires a valid project ID.
          command: |
            echo 'export GOOGLE_PROJECT_ID="moz-fx-telemetry-airflow-prod"' >> "$BASH_ENV"
            echo "export OIDC_WIP_ID=$GCPV2_WORKLOAD_IDENTITY_POOL_ID" >> "$BASH_ENV"
            echo "export OIDC_WIP_PROVIDER_ID=$GCPV2_CIRCLECI_WORKLOAD_IDENTITY_PROVIDER" >> "$BASH_ENV"
            echo "export GOOGLE_PROJECT_NUMBER=$GCPV2_WORKLOAD_IDENTITY_POOL_PROJECT_NUMBER" >> "$BASH_ENV"
            echo "export OIDC_SERVICE_ACCOUNT_EMAIL=$GCP_SERVICE_ACCOUNT_EMAIL" >> "$BASH_ENV"
      - gcp-cli/setup:
          use_oidc: true
      - run:
          name: Generate API Token and DAG run note
          command: |
            echo "export DAGRUN_NOTE=\"DAG triggered by **[${CIRCLE_USERNAME}](https://github.com/${CIRCLE_USERNAME})** from ${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME} CI build [${CIRCLE_BUILD_NUM}](${CIRCLE_BUILD_URL})\"" >> "$BASH_ENV"
            echo "export ID_TOKEN=$(gcloud auth print-identity-token --impersonate-service-account ${GCP_SERVICE_ACCOUNT_EMAIL})" >> "$BASH_ENV"
      - run:
          name: Trigger looker DAG in Airflow to deploy lookml
          command: >
            curl --location --request POST "https://us-west1-moz-fx-telemetry-airflow-prod.cloudfunctions.net/ci-external-trigger"
            -H "Authorization: bearer ${ID_TOKEN}"
            -H "Content-Type:application/json"
            -d "{\"dagrun_note\": \"${DAGRUN_NOTE}\", \"dag_id\":\"looker\"}"
  build-container:
    executor: docker/docker
    working_directory: ~/mozilla/lookml-generator
    steps:
      - checkout
      - setup_remote_docker
      - run: docker build -t app:build .
  deploy-to-gcr:
    executor: ubuntu-machine-executor
    steps:
      - checkout
      - gcp-gcr/gcr-auth:
          use_oidc: true
      - gcp-gcr/build-image: &image
          image: lookml-generator
          tag: ${CIRCLE_TAG:-latest}
      - gcp-gcr/push-image: *image
      - gcp-gcr/tag-image:
          image: lookml-generator
          source-tag: latest
          target-tag: $CIRCLE_SHA1

workflows:
  version: 2
  build-and-deploy:
    jobs:
      - unit-tests
      - integration-tests:
          context: data-eng-circleci-tests

      - verify-requirements
      - build-container
      - docs-build

      - generate-lookml:
          context: data-eng-circleci-tests
          filters:
            branches:
              ignore: main

      - generate-diff:
          requires:
            - generate-lookml
          filters:
            branches:
              ignore: main

      - docs-deploy:
          requires:
            - docs-build
            - unit-tests
            - verify-requirements
            - integration-tests
          filters:
            branches:
              only: main

      - deploy-to-gcr:
          context: dataeng-bqetl-gcr
          requires:
            - unit-tests
            - verify-requirements
            - integration-tests
            - build-container
          filters:
            branches:
              only: main

      - looker-deploy:
          name: Trigger looker Airflow DAG to deploy lookml
          context: gcpv2-workload-identity
          requires:
            - deploy-to-gcr
          filters:
            branches:
              only:
                - main
```

After migration:

```yaml
name: Build, Test, and Deploy
on:
  push:
    branches:
  pull_request:
  merge_group:

jobs:
  verify-requirements:
    name: Verify Requirements
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Verify requirements.txt dependencies
        run: |
          pip install pip-tools --constraint requirements.in
          pip-compile --allow-unsafe --generate-hashes --quiet
          git diff --exit-code -G '^ *[^# ]' -- requirements.txt

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m venv venv/
          venv/bin/pip install pip-tools --constraint requirements.in
          venv/bin/pip-sync
      - name: PyTest with linters
        run: venv/bin/pytest
      - name: Flake8
        run: venv/bin/flake8 generator
      - name: Lint YAML
        run: venv/bin/yamllint -c .yamllint.yaml .

  build-container:
    name: Build Container
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Build image
        run: docker build -t app:build .

  docs-build:
    name: Build Docs
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m venv venv/
          venv/bin/pip install pip-tools --constraint requirements.in
          venv/bin/pip-sync
      - name: Build docs
        run: |
          venv/bin/pip install pdoc
          venv/bin/pdoc -o /tmp/_html generator
      - name: Upload docs artifact
        uses: actions/upload-artifact@v4
        with:
          name: docs-html
          path: /tmp/_html

  generate-lookml:
    name: Generate LookML
    runs-on: ubuntu-latest
    if: |
      (github.event.pull_request.head.repo.full_name == github.repository || github.event_name != 'pull_request')
      && github.ref != 'refs/heads/main'
    permissions:
      id-token: write
      contents: read
    environment: GH Actions
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m venv venv/
          venv/bin/pip install pip-tools --constraint requirements.in
          venv/bin/pip-sync
      - name: Authenticate to GCP and Generate ID Token
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_DRYRUN_SERVICE_ACCOUNT_EMAIL }}
          token_format: 'id_token'
          id_token_audience: 'https://us-central1-moz-fx-data-shared-prod.cloudfunctions.net/bigquery-etl-dryrun'
          id_token_include_email: true
      - name: Export ID Token for Python
        env:
          GOOGLE_GHA_ID_TOKEN: ${{ steps.auth.outputs.id_token }}
        run: echo "GOOGLE_GHA_ID_TOKEN=$GOOGLE_GHA_ID_TOKEN" >> $GITHUB_ENV
      - name: Clone looker-hub
        uses: actions/checkout@v4
        with:
          repository: mozilla/looker-hub
          ref: main
          path: looker-hub
      - name: Generate LookML
        env:
          LOOKER_HUB_DIR: ${{ github.workspace }}/looker-hub
        run: |
          ./bin/generator namespaces
          cat namespaces.yaml
          ./bin/generator lookml --target-dir=/tmp/workspace/generated-lookml --use_cloud_function=True
      - name: Upload LookML artifact
        uses: actions/upload-artifact@v4
        with:
          name: generated-lookml
          path: /tmp/workspace/generated-lookml

  generate-diff:
    name: Generate and Post Diff
    runs-on: ubuntu-latest
    needs: generate-lookml
    if: |
      (github.event.pull_request.head.repo.full_name == github.repository || github.event_name != 'pull_request')
      && github.ref != 'refs/heads/main'
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Download LookML artifact
        uses: actions/download-artifact@v4
        with:
          name: generated-lookml
          path: /tmp/workspace/generated-lookml
      - name: Checkout looker-hub
        uses: actions/checkout@v4
        with:
          repository: mozilla/looker-hub
          ref: main
          path: looker-hub
          persist-credentials: false
      - name: Generate diff
        run: |
          # Copy looker-hub to /tmp/workspace for consistency with generated-lookml location
          mkdir -p /tmp/workspace
          cp -R looker-hub /tmp/workspace/looker-hub

          find /tmp/workspace/generated-lookml -type d -empty -delete

          cp -R /tmp/workspace/looker-hub/operational_monitoring /tmp/workspace/generated-lookml
          yq eval -i 'del(.operational_monitoring)' /tmp/workspace/generated-lookml/namespaces.yaml
          yq eval -i 'del(.operational_monitoring)' /tmp/workspace/looker-hub/namespaces.yaml

          rm /tmp/workspace/looker-hub/README.md
          rm /tmp/workspace/looker-hub/hub.model.lkml
          rm /tmp/workspace/looker-hub/CODE_OF_CONDUCT.md
          rm /tmp/workspace/looker-hub/firefox_ios/views/column_field_paths.view.lkml

          diff -x '.*' -qr --no-dereference \
            /tmp/workspace/looker-hub/ /tmp/workspace/generated-lookml/ \
            | grep '^Only in' \
            >> /tmp/workspace/lookml.diff || true
          diff -x '.*' -bur --no-dereference --new-file \
            /tmp/workspace/looker-hub/ /tmp/workspace/generated-lookml/ \
            >> /tmp/workspace/lookml.diff || true
      - name: Upload diff artifact
        uses: actions/upload-artifact@v4
        with:
          name: lookml-diff
          path: /tmp/workspace/lookml.diff
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '21'
      - name: Install diff dependencies
        run: npm i @octokit/graphql@7.0.2
      - name: Post diff to GitHub
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO_OWNER: ${{ github.repository_owner }}
          REPO_NAME: ${{ github.event.repository.name }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          RUN_ID: ${{ github.run_id }}
          COMMIT_MESSAGE: ${{ github.event.head_commit.message }}
        run: node .github/workflows/post-diff.js

  docs-deploy:
    name: Deploy Docs
    runs-on: ubuntu-latest
    needs: [docs-build, unit-tests, verify-requirements]
    if: github.ref == 'refs/heads/main'
    permissions:
      contents: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Download docs artifact
        uses: actions/download-artifact@v4
        with:
          name: docs-html
          path: /tmp/_html
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '14'
      - name: Install and configure dependencies
        run: |
          npm install -g --silent gh-pages@3.0.0
          git config user.email "ci-build-docs@mozilla.com"
          git config user.name "ci-build-docs"
      - name: Deploy docs to gh-pages branch
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh-pages --message "[skip ci] updates" --dist /tmp/_html \
          --repo https://x-access-token:$GITHUB_TOKEN@github.com/${{ github.repository }}.git

  deploy-to-gar:
    name: Deploy to GAR
    runs-on: ubuntu-latest
    needs: [unit-tests, verify-requirements, build-container]
    if: github.ref == 'refs/heads/main'
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Build the Docker image
        run: |
          docker build . -t lookml-generator:latest \
                         -t lookml-generator:${{ github.sha }}
      - name: Push Docker image to GAR
        uses: mozilla-it/deploy-actions/docker-push@v4.3.2
        with:
          project_id: moz-fx-data-artifacts-prod
          image_tags: |
            lookml-generator:latest
            lookml-generator:${{ github.sha }}
          workload_identity_pool_project_number: ${{ vars.GCPV2_WORKLOAD_IDENTITY_POOL_PROJECT_NUMBER }}
          service_account_name: lookml-generator

  looker-deploy:
    name: Trigger Looker Deploy DAG
    runs-on: ubuntu-latest
    needs: deploy-to-gar
    if: github.ref == 'refs/heads/main'
    permissions:
      id-token: write
      contents: read
    environment: GH Actions
    steps:
      - name: Authenticate to GCP and Generate ID Token
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ vars.GCPV2_GITHUB_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}
          token_format: id_token
          id_token_audience: https://us-west1-moz-fx-telemetry-airflow-prod.cloudfunctions.net/ci-external-trigger
          id_token_include_email: true
          create_credentials_file: false
      - name: Prepare DAG run note
        # yamllint disable
        run: |
          echo "DAGRUN_NOTE=DAG triggered by **[${{ github.actor }}](https://github.com/${{ github.actor }})** from ${{ github.repository }} CI build [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_ENV
        # yamllint enable
      - name: Trigger looker DAG in Airflow to deploy lookml
        env:
          ID_TOKEN: ${{ steps.auth.outputs.id_token }}
        run: |
          curl --location --request POST \
            "https://us-west1-moz-fx-telemetry-airflow-prod.cloudfunctions.net/ci-external-trigger" \
            -H "Authorization: bearer ${ID_TOKEN}" \
            -H "Content-Type:application/json" \
            -d "{\"dagrun_note\": \"${DAGRUN_NOTE}\", \"dag_id\":\"looker\"}"
```

# Checklist

* Add my-repo to dataservices-infra GAR access list?
* Configure repository secrets
* Test workflow on a branch first
* Verify Docker image pushes successfully

